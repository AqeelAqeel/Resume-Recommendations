{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1765c9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "665c339b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recruiter            2042\n",
       "Data Scientist       1597\n",
       "Financial Analyst    1523\n",
       "Physician            1462\n",
       "Underwriter          1403\n",
       "Chemical Engineer    1028\n",
       "Name: job_title, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/cleaned_job_descriptions')\n",
    "\n",
    "#Disparity / Class Balance Check\n",
    "df['job_title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84db2e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"job_id\"] = df[\"job_title\"].factorize()[0]\n",
    "job_id_df = df[['job_id', 'job_title']].drop_duplicates().sort_values('job_id')\n",
    "id_to_job = dict(job_id_df[['job_id', 'job_title']].values)\n",
    "# Setting targets and training data\n",
    "features = df['job_desc'].values\n",
    "targets = df['job_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1179cad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>1</td>\n",
       "      <td>Financial Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>2</td>\n",
       "      <td>Underwriter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2176</th>\n",
       "      <td>3</td>\n",
       "      <td>Chemical Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3204</th>\n",
       "      <td>4</td>\n",
       "      <td>Physician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4666</th>\n",
       "      <td>5</td>\n",
       "      <td>Recruiter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      job_id          job_title\n",
       "0          0     Data Scientist\n",
       "410        1  Financial Analyst\n",
       "773        2        Underwriter\n",
       "2176       3  Chemical Engineer\n",
       "3204       4          Physician\n",
       "4666       5          Recruiter"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_id_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "838717cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(stopWords, descriptions):\n",
    "    cleaned_descriptions = []\n",
    "    for description in descriptions:\n",
    "        temp_list = []\n",
    "        for word in description.split():\n",
    "            if word not in stopWords:\n",
    "                temp_list.append(word.lower())\n",
    "        cleaned_descriptions.append(' '.join(temp_list))\n",
    "    return np.array(cleaned_descriptions)\n",
    "\n",
    "def remove_punctuation(descriptions):\n",
    "    no_punct_descriptions = []\n",
    "    for description in descriptions:\n",
    "        description_no_punct = ' '.join(RegexpTokenizer(r'\\w+').tokenize(description))\n",
    "        no_punct_descriptions.append(description_no_punct)\n",
    "    return np.array(no_punct_descriptions)\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    # nltk.download()\n",
    "\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {'J': wordnet.ADJ,\n",
    "               'N': wordnet.NOUN,\n",
    "               'V': wordnet.VERB,\n",
    "               'R': wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def lemmatize_descriptions(descriptions):\n",
    "    cleaned_descriptions = []\n",
    "    for description in descriptions:\n",
    "        temp_list = []\n",
    "        for word in description.split():\n",
    "            cleaned_word = WordNetLemmatizer().lemmatize(word, get_wordnet_pos(word))\n",
    "            temp_list.append(cleaned_word)\n",
    "        cleaned_descriptions.append(' '.join(temp_list))\n",
    "    return np.array(cleaned_descriptions)\n",
    "\n",
    "def clean_descriptions(stopWords, descriptions):\n",
    "    no_punct = remove_punctuation(descriptions)\n",
    "    no_punct_sw = remove_stopwords(stopWords, no_punct)\n",
    "    cleaned = lemmatize_descriptions(no_punct_sw)\n",
    "    return cleaned\n",
    "\n",
    "def get_representative_jobs(df, kmeans):\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    for cent in cluster_centers:\n",
    "        print('\\nCluster Represnetations')\n",
    "        dist = euclidean_distances(cent.reshape(1,-1), tfidf)\n",
    "        order = np.argsort(dist)\n",
    "        for o in order[0][:5]:\n",
    "            title = df['job_title'].iloc[o]\n",
    "            print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c55d937a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr path is:\n",
      "/home/aqeelali7/Documents/Galvanize/Capstone-3-ATS/The-Right-Resume/src\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    import os\n",
    "    print(\"curr path is:\")\n",
    "    print(os.getcwd())\n",
    "    \n",
    "    \n",
    "    # Setting targets and training data\n",
    "    descriptions = df['job_desc'].values\n",
    "    targets = df['job_id']\n",
    "    \n",
    "    \n",
    "    # Creating stop words\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    add_stopwords = {\n",
    "        'join', 'work', 'team', 'future', 'digital', 'technology', 'access', 'leader', 'industry', 'history', 'innovation',\n",
    "        'year', 'customer', 'focused', 'leading', 'business', 'ability', 'country', 'employee', 'www', 'seeking',\n",
    "        'location', 'role', 'responsible', 'designing', 'code', 'ideal', 'candidate', 'also', 'duty', 'without', 'excellent',\n",
    "        'set', 'area', 'well', 'use', 'strong', 'self', 'help', 'diverse', 'every', 'day', 'equal', 'employment', 'opportunity',\n",
    "        'affirmative', 'action', 'employer', 'diversity', 'qualified', 'applicant', 'receive', 'consideration', 'regard',\n",
    "        'race', 'color', 'religion', 'sex', 'national', 'origin', 'status', 'age', 'sexual', 'orientation', 'gender',\n",
    "        'identity', 'disability', 'marital', 'family', 'medical', 'protected', 'veteran', 'reasonable', 'accomodation',\n",
    "        'protect', 'status', 'equal', 'discriminate', 'hire', 'hiring','inclusive', 'diverse','benefits','vacation','000','10','nike',\"trustpilot\"\n",
    "    }\n",
    "    \n",
    "    stopWords = stopWords.union(add_stopwords)\n",
    "\n",
    "    # Initializing punctuation remover and lemmatizer\n",
    "    tokenize_remove_punct = RegexpTokenizer(r'\\w+')\n",
    "    lemma = WordNetLemmatizer()\n",
    "\n",
    "    # Cleaning descriptions for both the whole dataset and CO only\n",
    "    cleaned_descriptions = clean_descriptions(stopWords, descriptions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d1808596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "def _split_data(df):\n",
    "\n",
    "    return train_test_split(cleaned_descriptions, df['job_title'].values)\n",
    "\n",
    "def fit(model, X,y):\n",
    "    pipe = Pipeline([('vect', CountVectorizer(stop_words=stopWords, min_df=0.1, max_df=0.75, max_features=500,ngram_range=(1, 2))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', model),\n",
    "    ])\n",
    "    pipe.fit(X,y)\n",
    "    \n",
    "    return pipe\n",
    "\n",
    "def predict(pipe,X_test):\n",
    "    return pipe.predict(X_test)\n",
    "\n",
    "def predict_one(pipe, desc):\n",
    "    return pipe.predict(pd.Series([desc])).tolist()[0]\n",
    "\n",
    "def predict_one_proba(pipe, desc):\n",
    "    return pipe.predict_proba(pd.Series([desc]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "93574a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "685e43d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "173d09de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('vect',\n",
      "                 CountVectorizer(max_df=0.75, max_features=500, min_df=0.1,\n",
      "                                 ngram_range=(1, 2),\n",
      "                                 stop_words={'000', '10', 'a', 'ability',\n",
      "                                             'about', 'above', 'access',\n",
      "                                             'accomodation', 'action',\n",
      "                                             'affirmative', 'after', 'again',\n",
      "                                             'against', 'age', 'ain', 'all',\n",
      "                                             'also', 'am', 'an', 'and', 'any',\n",
      "                                             'applicant', 'are', 'area', 'aren',\n",
      "                                             \"aren't\", 'as', 'at', 'be',\n",
      "                                             'because', ...})),\n",
      "                ('tfidf', TfidfTransformer()),\n",
      "                ('clf',\n",
      "                 RandomForestClassifier(max_depth=3, n_estimators=200,\n",
      "                                        random_state=0))])\n",
      "0.9213780918727915\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Chemical Engineer       0.92      0.99      0.95       255\n",
      "   Data Scientist       0.85      0.94      0.90       366\n",
      "Financial Analyst       0.90      0.93      0.92       343\n",
      "        Physician       0.91      0.96      0.94       364\n",
      "        Recruiter       0.98      0.81      0.89       602\n",
      "      Underwriter       0.95      0.99      0.97       334\n",
      "\n",
      "         accuracy                           0.92      2264\n",
      "        macro avg       0.92      0.94      0.93      2264\n",
      "     weighted avg       0.93      0.92      0.92      2264\n",
      "\n",
      "Pipeline(steps=[('vect',\n",
      "                 CountVectorizer(max_df=0.75, max_features=500, min_df=0.1,\n",
      "                                 ngram_range=(1, 2),\n",
      "                                 stop_words={'000', '10', 'a', 'ability',\n",
      "                                             'about', 'above', 'access',\n",
      "                                             'accomodation', 'action',\n",
      "                                             'affirmative', 'after', 'again',\n",
      "                                             'against', 'age', 'ain', 'all',\n",
      "                                             'also', 'am', 'an', 'and', 'any',\n",
      "                                             'applicant', 'are', 'area', 'aren',\n",
      "                                             \"aren't\", 'as', 'at', 'be',\n",
      "                                             'because', ...})),\n",
      "                ('tfidf', TfidfTransformer()), ('clf', LinearSVC())])\n",
      "0.9721731448763251\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Chemical Engineer       0.98      0.99      0.99       272\n",
      "   Data Scientist       0.96      0.96      0.96       404\n",
      "Financial Analyst       0.97      0.93      0.95       370\n",
      "        Physician       0.98      0.98      0.98       386\n",
      "        Recruiter       0.97      0.99      0.98       485\n",
      "      Underwriter       0.98      0.99      0.98       347\n",
      "\n",
      "         accuracy                           0.97      2264\n",
      "        macro avg       0.97      0.97      0.97      2264\n",
      "     weighted avg       0.97      0.97      0.97      2264\n",
      "\n",
      "Pipeline(steps=[('vect',\n",
      "                 CountVectorizer(max_df=0.75, max_features=500, min_df=0.1,\n",
      "                                 ngram_range=(1, 2),\n",
      "                                 stop_words={'000', '10', 'a', 'ability',\n",
      "                                             'about', 'above', 'access',\n",
      "                                             'accomodation', 'action',\n",
      "                                             'affirmative', 'after', 'again',\n",
      "                                             'against', 'age', 'ain', 'all',\n",
      "                                             'also', 'am', 'an', 'and', 'any',\n",
      "                                             'applicant', 'are', 'area', 'aren',\n",
      "                                             \"aren't\", 'as', 'at', 'be',\n",
      "                                             'because', ...})),\n",
      "                ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
      "0.9372791519434629\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Chemical Engineer       0.96      0.97      0.96       273\n",
      "   Data Scientist       0.90      0.93      0.91       390\n",
      "Financial Analyst       0.89      0.92      0.91       344\n",
      "        Physician       0.94      0.94      0.94       387\n",
      "        Recruiter       0.96      0.92      0.94       517\n",
      "      Underwriter       0.97      0.96      0.97       353\n",
      "\n",
      "         accuracy                           0.94      2264\n",
      "        macro avg       0.94      0.94      0.94      2264\n",
      "     weighted avg       0.94      0.94      0.94      2264\n",
      "\n",
      "Pipeline(steps=[('vect',\n",
      "                 CountVectorizer(max_df=0.75, max_features=500, min_df=0.1,\n",
      "                                 ngram_range=(1, 2),\n",
      "                                 stop_words={'000', '10', 'a', 'ability',\n",
      "                                             'about', 'above', 'access',\n",
      "                                             'accomodation', 'action',\n",
      "                                             'affirmative', 'after', 'again',\n",
      "                                             'against', 'age', 'ain', 'all',\n",
      "                                             'also', 'am', 'an', 'and', 'any',\n",
      "                                             'applicant', 'are', 'area', 'aren',\n",
      "                                             \"aren't\", 'as', 'at', 'be',\n",
      "                                             'because', ...})),\n",
      "                ('tfidf', TfidfTransformer()),\n",
      "                ('clf', LogisticRegression(random_state=0))])\n",
      "0.9664310954063604\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Chemical Engineer       0.98      0.99      0.98       273\n",
      "   Data Scientist       0.95      0.96      0.95       399\n",
      "Financial Analyst       0.96      0.91      0.93       373\n",
      "        Physician       0.98      0.98      0.98       386\n",
      "        Recruiter       0.97      0.98      0.98       489\n",
      "      Underwriter       0.97      0.99      0.98       344\n",
      "\n",
      "         accuracy                           0.97      2264\n",
      "        macro avg       0.97      0.97      0.97      2264\n",
      "     weighted avg       0.97      0.97      0.97      2264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = _split_data(df)\n",
    "\n",
    "for model in models:\n",
    "    model = fit(model,X_train,y_train)\n",
    "    predictions = predict(model,X_test)\n",
    "    print(model)\n",
    "    print(accuracy_score(predictions,y_test))\n",
    "    print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7050dc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('vect',\n",
      "                 CountVectorizer(max_df=0.75, max_features=500, min_df=0.1,\n",
      "                                 ngram_range=(1, 2),\n",
      "                                 stop_words={'000', '10', 'a', 'ability',\n",
      "                                             'about', 'above', 'access',\n",
      "                                             'accomodation', 'action',\n",
      "                                             'affirmative', 'after', 'again',\n",
      "                                             'against', 'age', 'ain', 'all',\n",
      "                                             'also', 'am', 'an', 'and', 'any',\n",
      "                                             'applicant', 'are', 'area', 'aren',\n",
      "                                             \"aren't\", 'as', 'at', 'be',\n",
      "                                             'because', ...})),\n",
      "                ('tfidf', TfidfTransformer()),\n",
      "                ('clf',\n",
      "                 RandomForestClassifier(max_depth=3, n_estimators=200,\n",
      "                                        random_state=0))])\n",
      "0.9257950530035336\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Chemical Engineer       0.86      1.00      0.93       229\n",
      "   Data Scientist       0.87      0.93      0.90       371\n",
      "Financial Analyst       0.93      0.96      0.94       358\n",
      "        Physician       0.91      0.96      0.93       341\n",
      "        Recruiter       0.98      0.82      0.89       615\n",
      "      Underwriter       0.96      0.99      0.98       350\n",
      "\n",
      "         accuracy                           0.93      2264\n",
      "        macro avg       0.92      0.94      0.93      2264\n",
      "     weighted avg       0.93      0.93      0.92      2264\n",
      "\n",
      "Pipeline(steps=[('vect',\n",
      "                 CountVectorizer(max_df=0.75, max_features=500, min_df=0.1,\n",
      "                                 ngram_range=(1, 2),\n",
      "                                 stop_words={'000', '10', 'a', 'ability',\n",
      "                                             'about', 'above', 'access',\n",
      "                                             'accomodation', 'action',\n",
      "                                             'affirmative', 'after', 'again',\n",
      "                                             'against', 'age', 'ain', 'all',\n",
      "                                             'also', 'am', 'an', 'and', 'any',\n",
      "                                             'applicant', 'are', 'area', 'aren',\n",
      "                                             \"aren't\", 'as', 'at', 'be',\n",
      "                                             'because', ...})),\n",
      "                ('tfidf', TfidfTransformer()), ('clf', LinearSVC())])\n",
      "0.9690812720848057\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Chemical Engineer       0.97      0.99      0.98       259\n",
      "   Data Scientist       0.96      0.95      0.96       395\n",
      "Financial Analyst       0.96      0.94      0.95       376\n",
      "        Physician       0.98      0.96      0.97       367\n",
      "        Recruiter       0.97      0.98      0.97       507\n",
      "      Underwriter       0.98      0.99      0.99       360\n",
      "\n",
      "         accuracy                           0.97      2264\n",
      "        macro avg       0.97      0.97      0.97      2264\n",
      "     weighted avg       0.97      0.97      0.97      2264\n",
      "\n",
      "Pipeline(steps=[('vect',\n",
      "                 CountVectorizer(max_df=0.75, max_features=500, min_df=0.1,\n",
      "                                 ngram_range=(1, 2),\n",
      "                                 stop_words={'000', '10', 'a', 'ability',\n",
      "                                             'about', 'above', 'access',\n",
      "                                             'accomodation', 'action',\n",
      "                                             'affirmative', 'after', 'again',\n",
      "                                             'against', 'age', 'ain', 'all',\n",
      "                                             'also', 'am', 'an', 'and', 'any',\n",
      "                                             'applicant', 'are', 'area', 'aren',\n",
      "                                             \"aren't\", 'as', 'at', 'be',\n",
      "                                             'because', ...})),\n",
      "                ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
      "0.9425795053003534\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Chemical Engineer       0.95      0.96      0.95       263\n",
      "   Data Scientist       0.88      0.93      0.91       375\n",
      "Financial Analyst       0.91      0.93      0.92       362\n",
      "        Physician       0.96      0.94      0.95       368\n",
      "        Recruiter       0.97      0.94      0.95       531\n",
      "      Underwriter       0.98      0.97      0.98       365\n",
      "\n",
      "         accuracy                           0.94      2264\n",
      "        macro avg       0.94      0.94      0.94      2264\n",
      "     weighted avg       0.94      0.94      0.94      2264\n",
      "\n",
      "Pipeline(steps=[('vect',\n",
      "                 CountVectorizer(max_df=0.75, max_features=500, min_df=0.1,\n",
      "                                 ngram_range=(1, 2),\n",
      "                                 stop_words={'000', '10', 'a', 'ability',\n",
      "                                             'about', 'above', 'access',\n",
      "                                             'accomodation', 'action',\n",
      "                                             'affirmative', 'after', 'again',\n",
      "                                             'against', 'age', 'ain', 'all',\n",
      "                                             'also', 'am', 'an', 'and', 'any',\n",
      "                                             'applicant', 'are', 'area', 'aren',\n",
      "                                             \"aren't\", 'as', 'at', 'be',\n",
      "                                             'because', ...})),\n",
      "                ('tfidf', TfidfTransformer()),\n",
      "                ('clf', LogisticRegression(random_state=0))])\n",
      "0.9642226148409894\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Chemical Engineer       0.97      0.98      0.97       262\n",
      "   Data Scientist       0.94      0.96      0.95       387\n",
      "Financial Analyst       0.95      0.93      0.94       376\n",
      "        Physician       0.98      0.96      0.97       367\n",
      "        Recruiter       0.97      0.97      0.97       512\n",
      "      Underwriter       0.98      0.99      0.98       360\n",
      "\n",
      "         accuracy                           0.96      2264\n",
      "        macro avg       0.96      0.96      0.96      2264\n",
      "     weighted avg       0.96      0.96      0.96      2264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = _split_data(df)\n",
    "\n",
    "for model in models:\n",
    "    model = fit(model,X_train,y_train)\n",
    "    predictions = predict(model,X_test)\n",
    "    print(model)\n",
    "    print(accuracy_score(predictions,y_test))\n",
    "    print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "dcb8f193",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('engineering', 5.812884517382459),\n",
       " ('chemical', 4.712295358584039),\n",
       " ('process', 3.3048327501090746),\n",
       " ('engineer', 2.759538904831979),\n",
       " ('technical', 2.6897635700565186),\n",
       " ('design', 2.648244712123161),\n",
       " ('project', 2.383216962930082),\n",
       " ('material', 2.2253868968407247),\n",
       " ('equipment', 2.098554906359399),\n",
       " ('financial', 1.8383713592522883),\n",
       " ('site', 1.736766154276616),\n",
       " ('data', 1.7146784276851945),\n",
       " ('test', 1.7017944146698294),\n",
       " ('development', 1.6171800362083144),\n",
       " ('control', 1.5457290016245644),\n",
       " ('production', 1.4558224400111832),\n",
       " ('quality', 1.395976453704809),\n",
       " ('safety', 1.3878334282192508),\n",
       " ('product', 1.3274463465553692),\n",
       " ('operation', 1.2090783916079653),\n",
       " ('system', 1.125948592082455),\n",
       " ('recruiting', 1.073447154793133),\n",
       " ('discipline', 1.0363500759253854),\n",
       " ('underwriting', 1.0277104340657126),\n",
       " ('analytics', 1.0130320285914842),\n",
       " ('integrity', 0.9859767067295652),\n",
       " ('clinical', 0.9830058642168892),\n",
       " ('company', 0.9395293996037173),\n",
       " ('science', 0.930673531378669),\n",
       " ('develop', 0.912754803550862),\n",
       " ('finance', 0.824694281153711),\n",
       " ('improvement', 0.8243990302366279),\n",
       " ('care', 0.8210341388919354),\n",
       " ('facility', 0.8128153177682949),\n",
       " ('drive', 0.7840067464606153),\n",
       " ('environment', 0.7772930364379388),\n",
       " ('accounting', 0.7696879838331742),\n",
       " ('travel', 0.7696326834045523),\n",
       " ('result', 0.7335523387701177),\n",
       " ('analyst', 0.7312231510575106),\n",
       " ('multiple', 0.6946998040945556),\n",
       " ('characteristic', 0.6900167953423688),\n",
       " ('community', 0.6896237300375282),\n",
       " ('successful', 0.6784663187009305),\n",
       " ('hand', 0.6744433370998189),\n",
       " ('information', 0.662253528358517),\n",
       " ('activity', 0.6584690244212371),\n",
       " ('patient', 0.6579306883961914),\n",
       " ('life', 0.6513652237122033),\n",
       " ('support', 0.6489655744260362),\n",
       " ('review', 0.648516351925356),\n",
       " ('university', 0.6437289805608214),\n",
       " ('computer', 0.6410561058732283),\n",
       " ('technique', 0.6407080750409009),\n",
       " ('source', 0.6376989369564869),\n",
       " ('scale', 0.6358105424123786),\n",
       " ('group', 0.6022945906765206),\n",
       " ('physician', 0.5925021536503047),\n",
       " ('deep', 0.5921334767370103),\n",
       " ('related', 0.5872232233932669),\n",
       " ('machine learn', 0.5849911820593708),\n",
       " ('execute', 0.5789867457472164),\n",
       " ('home', 0.5773696994995154),\n",
       " ('software', 0.5687889330458967),\n",
       " ('data science', 0.5670213070961353),\n",
       " ('manager', 0.5653802559512133),\n",
       " ('college', 0.5626950232406347),\n",
       " ('compliance', 0.5620502102186028),\n",
       " ('remote', 0.5565420398512478),\n",
       " ('schedule', 0.5534059090225386),\n",
       " ('value', 0.5460150114967542),\n",
       " ('talent', 0.5402921973859329),\n",
       " ('director', 0.5386857375687644),\n",
       " ('processing', 0.5378360376948419),\n",
       " ('problem solve', 0.5303159882373606),\n",
       " ('field', 0.5287264418529218),\n",
       " ('impact', 0.5274190479761376),\n",
       " ('underwriter', 0.5262034542877597),\n",
       " ('public', 0.5248192919455273),\n",
       " ('mental', 0.5135985811021465),\n",
       " ('per', 0.5131097420868753),\n",
       " ('call', 0.512543786474115),\n",
       " ('expression', 0.5104993597743038),\n",
       " ('effective', 0.5029128560971564),\n",
       " ('enable', 0.5020986124512906),\n",
       " ('strategy', 0.49553954818994206),\n",
       " ('manage', 0.4940369529118282),\n",
       " ('event', 0.49311845405435256),\n",
       " ('time', 0.4928269146114199),\n",
       " ('requirement', 0.492446462706507),\n",
       " ('part', 0.4877483860495242),\n",
       " ('risk', 0.48727617778504545),\n",
       " ('new', 0.4851229445094032),\n",
       " ('high', 0.4817328180518588),\n",
       " ('sale', 0.47938778008297284),\n",
       " ('execution', 0.4732980645305309),\n",
       " ('recruiter', 0.47228696821843),\n",
       " ('platform', 0.4717110204276262),\n",
       " ('benefit', 0.4709741757159552),\n",
       " ('improve', 0.47096527849478437)]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = model.named_steps.clf.coef_\n",
    "feats = model.named_steps.vect.get_feature_names()\n",
    "\n",
    "# take coefficients and feature names, sorted? \n",
    "\n",
    "dct = {\"feats\":feats,\"coef\":coefs[0,:].tolist()}\n",
    "\n",
    "titles = [\"Chemical Engineer\",\"Data Scientist\",\"Financial Analyst\",\"Physician\",\"Recruiter\",\"Underwriter\"]\n",
    "\n",
    "d = dict()\n",
    "for i,title in enumerate(titles):\n",
    "    coefs[i,:]\n",
    "    dct = {\"feats\":feats,\"coef\":coefs[i,:].tolist()}\n",
    "    top_words_df = pd.DataFrame(dct)\n",
    "    top_words_df[\"coef\"] = top_words_df[\"coef\"].abs()\n",
    "    top_words_df = top_words_df.sort_values(\"coef\",ascending = False)\n",
    "    a = top_words_df.feats.values.tolist()[:100]\n",
    "    b = top_words_df.coef.values.tolist()[:100]\n",
    "    d[title] = list(zip(a,b))\n",
    "    \n",
    "\n",
    "# print(\"# '{}':\".format(job))\n",
    "# print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-N:])))\n",
    "\n",
    "d[\"Chemical Engineer\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4013dbbd",
   "metadata": {},
   "source": [
    "using dict of words... co\n",
    "Use dict key value for word comparisons to resume\n",
    "but only output the top keywords in each resume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc10d842",
   "metadata": {},
   "source": [
    " turn the top keywords of FA into a set. This set is what the model builds as a profile of an FA. \n",
    "    if 'analy' is in 'word':\n",
    "        word = analysis\n",
    "        \n",
    "- if word.startswith('analy'):\n",
    "    word = 'analysis\n",
    "    change the keyword itself to something else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e1d52c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9606890459363958\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Chemical Engineer       0.97      0.98      0.98       236\n",
      "   Data Scientist       0.94      0.94      0.94       391\n",
      "Financial Analyst       0.96      0.94      0.95       372\n",
      "        Physician       0.95      0.95      0.95       356\n",
      "        Recruiter       0.96      0.97      0.97       549\n",
      "      Underwriter       0.98      0.98      0.98       360\n",
      "\n",
      "         accuracy                           0.96      2264\n",
      "        macro avg       0.96      0.96      0.96      2264\n",
      "     weighted avg       0.96      0.96      0.96      2264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = _split_data(df)\n",
    "model = fit(LogisticRegression(),X_train,y_train)\n",
    "predictions = predict(model,X_test)\n",
    "print(accuracy_score(predictions,y_test))\n",
    "print(classification_report(predictions,y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "83b38243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'LogisticRegression.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "57dc3ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = \"AQEEL ALI Aqeelali0312@gmail.com | (408) 718-0712 | www.linkedin.com/in/aqeelali786 EDUCATION: California Polytechnic University, San Luis Obispo, CA B.S. Business Administration – Financial Management Concentration Minor in Psychology ● Honors: Principal’s List (3.5+ GPA for three consecutive academic terms) - Fall 2019 ● Relevant Coursework: Financial Engineering in Risk Management, Computer Applications in Finance, Advanced Corporate Finance Chartered Financial Analyst Level Two Candidate Exam Date: Nov 2021 ● Pursuing CFA designation by acquiring a wide breadth of portfolio management skills. ● Level One Exam passed on June 2019. WORK EXPERIENCE: Middle Market Portfolio Analyst – Comerica Bank, San Jose, CA Jul 2019 to Present ● Analyze employer’s Middle Market business for the California region through industry, financial, macroeconomic data and other supporting credit information concerning an applicant's credit requests. ● Identify key business and financial risks that may impact the repayment prospects by the borrower. ● Expertise in Salesforce Data Management and CRM software systems utilized while underwriting to 8-figure commercial banking facilities ranging from $5M to $100M loans and facilities. aggregate exposure of bank assets. ● Prepare, review and assess the creditworthiness of commercial loan originations and renewals by evaluating tax returns, spreads of financial statements, historical trends, rent rolls, leases, projections, management performance, industry reports, cash flow models, capital structure and collateral analysis and other relevant data to analyze portfolio companies’ repayment capacity. ● Ensure the integrity of performance data for clientele and prospects and maintain ongoing relationships with thecustodial partners banks, vendors, and internal groups. ● Offer insights into customer financial needs, including opportunities identified using Line of Business-approved relationship expansion tools. Contribute personal insights related to a loan structure's effectiveness to mitigate risks, appropriate to prevailing competitive market environment and Bank risk tolerances. ● Prepared & presented nation-wide internal quarterly Company Q1 & Q2 2020 earnings reports and portfolio updates (within a team of four). ● Undertook special project initiative while fluidly adapting self-starter work ethic to a remote work environment during the initial rollout of Federal Treasury Payroll Protection Program and reviewed numerous applicants’ eligibility & fund usage during COVID-19 global pandemic. Venture Capital Analyst Intern - LDR Ventures, San Luis Obispo, CA Jan 2019 to Apr 2019 ● Analyzed investment opportunities up to $1.5M, prepared fundraising pitches to external stakeholders and prospective investors, and identified potential risks for early stage portfolio companies ● Assisted in building pricing models to help companies launch multiple new product lines and conduct stress tests under varying scenario analyses. ● Oversaw a personally proposed initiative for a portfolio company’s marketing campaign across universities in California. LEADERSHIP & OTHER RELEVANT EXPERIENCE Banking Valuations, Investment Banking Society San Luis Obispo, CA Jan 2019 to Feb 2019 ● Took an extracurricular course which covered the three main methods of company valuations ● Competed in a Goldman Sachs case competition against over 20 teams to create a pitch deck and presentation for a real case study. Recommended a company’s IPO by analyzing their financial position, creating a pro forma financial model, computing value with several valuation methodologies and examining IPO market conditions Member - MacIntalkers of Toastmasters International Apple Cupertino, CA Jul 2018 to Feb 2020 ● Delivered five public speeches under the “Dynamic Leadership” Pathways project. ● Developed effective communication skills on a weekly basis. \" \n",
    "lyft_job_desc = \"Financial Analyst, Strategy Finance at Lyft San Francisco, CA At Lyft, our mission is to improve people’s lives with the world’s best transportation. To do this, we start with our own community by creating an open, inclusive, and diverse organization.  Lyft is hiring a Financial Analyst for its Strategy Finance Team. The candidate in this position will provide financial and analytical support to drive strategic decisions for the company and help prepare financial management reporting. As a Financial Analyst, you will work directly with stakeholders across Finance in forecasting, planning and reporting key metrics to senior leadership.  Responsibilities: Help in analyzing & modeling forecast trends for total company financials Assist in the preparation and analysis of consolidated P&L for actuals and forecasts, help the FP&A team on deliverables, ongoing variance analysis, and ad hoc modeling Help lead the FP&A team through weekly and monthly forecasting Assist in the quarterly and annual strategic planning process Collaborate with Investor Relations by analyzing relevant financial information in preparation for the earnings call and investor presentations Team up with Corporate Development to create Board of Directors financials Partner with FP&A, Accounting, Treasury, Tax, and HR to forecast centralized expenses Drive monthly and quarterly close activities for FP&A and support consolidated management reporting Partner with Accounting to manage close timelines, process and reporting Manage creation of internal executive reporting documents including board, close and other management presentations and workbooks Support initiatives to create process efficiencies & improvements within FP&A Experience: BA/BS with 3+ years of experience in financial planning and analytics (FP&A) in a rigorous environment Corporate Finance, forecasting, or consolidations experience is a plus Detail-oriented and organized self-starter with a drive to dig into complex problems Advanced Excel skills. Experience building complex formulas and manipulating large data sets Ability to work in a fast-paced, team-based environment with minimal supervision Research, quantitative and analytical skills Comfortable navigating through financial statements Ability to organize and track overlapping tasks and assignments, with frequent priority changes Strong interpersonal and communication skills, with the ability to communicate and influence effectively across various departments Benefits: Great medical, dental, and vision insurance options Mental health benefits In addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off 401(k) plan to help save for your future 18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible Pre-tax commuter benefits Lyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership Program \" \n",
    "cmgr_job_desc = \"About the Role: Raydiant is looking for a lover of technology, a customer-success driven channel manager to help build the channel and achieve set goals.  Customer Success Managers (Channel) coordinate and work closely with various channel partners and affiliates to build and grow the pipeline and sell our solutions to businesses. As a channel customer success manager, you will manage Raydiant’s business relationships within the US; working with customers from many different industries. You will help us achieve our mission of managing the channel partners we have, qualify and recruit more qualified partners to help drive business and grow the channel side of the business. This role is based in the office at our San Francisco, CA headquarters in the SOMA neighborhood. What You Will Be Doing:  Prospecting, qualifying and on-boarding channel partners that can help the company drive business growth month over month Be able to forecast monthly sales revenue and achieve sales goals and KPIs set by management hannel customer success managers will help manage all partners with a focus on creating yearly and quarterly channel plans Be able to travel and meet channel partners, to conduct presentations and live demos of the product Channel customer success managers will focus on training Raydiant partners on effective methods for selling, using the partner portal and using Raydiant’s product Channel customer success managers will build an excellent relationship with channel partners and have a focus on retaining sophisticated partners while coaching inexperienced Raydiant partners on the best sales practices. Channel customer success managers will create monthly sales reports and communicate channel partners monthly commission to them in coordination with the finance department To own management of the channel PRM To conduct webinars to attract new partners and conduct training sessions on new products and services   What We Are Looking For:   Passion for sales in B2B The motivation to go the extra mile with a positive can-do attitude Bachelor’s degree or equivalent experience Excellent communication and relationship-building relationship skills; you like to negotiate and to achieve targets  Strong software and new technology awareness At least 2-years experience in channel sales within a SaaS product line Proficient with Salesforce\"  \n",
    "ds_1_desc = \"We are looking for a Data Scientist who will support our product, sales, leadership and marketing teams with insights gained from analyzing company data. The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.Responsibilities for Data ScientistWork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.Assess the effectiveness and accuracy of new data sources and data gathering techniques.Develop custom data models and algorithms to apply to data sets.Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.Develop company A/B testing framework and test model quality.Coordinate with different functional teams to implement models and monitor outcomes.Develop processes and tools to monitor and analyze model performance and data accuracy.Qualifications for Data ScientistStrong problem solving skills with an emphasis on product development.Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.Experience working with and creating data architectures.Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.Excellent written and verbal communication skills for coordinating across teams.A drive to learn and master new technologies and techniques.We’re looking for someone with 5-7 years of experience manipulating data sets and building statistical models, has a Master’s or PHD in Statistics, Mathematics, Computer Science or another quantitative field, and is familiar with the following software/tools:Coding knowledge and experience with several languages: C, C++, Java,JavaScript, etc.Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.Experience querying databases and using statistical computer languages: R, Python, SLQ, etc.Experience using web services: Redshift, S3, Spark, DigitalOcean, etc.Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "29903e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Financial Analyst\n",
      "[[0.0010954  0.01225845 0.94344059 0.00121572 0.00100111 0.04098873]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Financial Analyst'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(predict_one(model, resume))\n",
    "print(predict_one_proba(model, resume))\n",
    "label = predict_one(model, resume)\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c8abe3",
   "metadata": {},
   "source": [
    "##  Display Top keywords for predicted job classification\n",
    "\n",
    "- use split method on input string (resume in this case), \n",
    "- clean text of resume - like punctuation and stuff. \n",
    "- populate a split and add an item to a SET if the item is not in the SET.\n",
    "- clean the items within the set with stemming\n",
    "- on words that i manually truncate like finance, engineer, tell te user to 'add variations of the word \"{word_here}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707dd0a0",
   "metadata": {},
   "source": [
    "\n",
    "take predicted class (job title in this case)\n",
    "- compare words in resume against top 30~50 words\n",
    "- suggest top 5-10 words needed.\n",
    "- create a set of words based on resume, compared against pickled model of top keywords. \n",
    "- if i am missing ___ in my input, tell it to put ___ there. \n",
    "\n",
    "Get a list of all words in resume\n",
    "    iterate through top words in the job (keywords_fa) set, \n",
    "        if topwords_FA not in resume:\n",
    "            print top 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "1accfedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = \"AQEEL ALI Aqeelali0312@gmail.com | (408) 718-0712 | www.linkedin.com/in/aqeelali786 EDUCATION: California Polytechnic University, San Luis Obispo, CA B.S. Business Administration – Financial Management Concentration Minor in Psychology ● Honors: Principal’s List (3.5+ GPA for three consecutive academic terms) - Fall 2019 ● Relevant Coursework: Financial Engineering in Risk Management, Computer Applications in Finance, Advanced Corporate Finance Chartered Financial Analyst Level Two Candidate Exam Date: Nov 2021 ● Pursuing CFA designation by acquiring a wide breadth of portfolio management skills. ● Level One Exam passed on June 2019. WORK EXPERIENCE: Middle Market Portfolio Analyst – Comerica Bank, San Jose, CA Jul 2019 to Present ● Analyze employer’s Middle Market business for the California region through industry, financial, macroeconomic data and other supporting credit information concerning an applicant's credit requests. ● Identify key business and financial risks that may impact the repayment prospects by the borrower. ● Expertise in Salesforce Data Management and CRM software systems utilized while underwriting to 8-figure commercial banking facilities ranging from $5M to $100M loans and facilities. aggregate exposure of bank assets. ● Prepare, review and assess the creditworthiness of commercial loan originations and renewals by evaluating tax returns, spreads of financial statements, historical trends, rent rolls, leases, projections, management performance, industry reports, cash flow models, capital structure and collateral analysis and other relevant data to analyze portfolio companies’ repayment capacity. ● Ensure the integrity of performance data for clientele and prospects and maintain ongoing relationships with thecustodial partners banks, vendors, and internal groups. ● Offer insights into customer financial needs, including opportunities identified using Line of Business-approved relationship expansion tools. Contribute personal insights related to a loan structure's effectiveness to mitigate risks, appropriate to prevailing competitive market environment and Bank risk tolerances. ● Prepared & presented nation-wide internal quarterly Company Q1 & Q2 2020 earnings reports and portfolio updates (within a team of four). ● Undertook special project initiative while fluidly adapting self-starter work ethic to a remote work environment during the initial rollout of Federal Treasury Payroll Protection Program and reviewed numerous applicants’ eligibility & fund usage during COVID-19 global pandemic. Venture Capital Analyst Intern - LDR Ventures, San Luis Obispo, CA Jan 2019 to Apr 2019 ● Analyzed investment opportunities up to $1.5M, prepared fundraising pitches to external stakeholders and prospective investors, and identified potential risks for early stage portfolio companies ● Assisted in building pricing models to help companies launch multiple new product lines and conduct stress tests under varying scenario analyses. ● Oversaw a personally proposed initiative for a portfolio company’s marketing campaign across universities in California. LEADERSHIP & OTHER RELEVANT EXPERIENCE Banking Valuations, Investment Banking Society San Luis Obispo, CA Jan 2019 to Feb 2019 ● Took an extracurricular course which covered the three main methods of company valuations ● Competed in a Goldman Sachs case competition against over 20 teams to create a pitch deck and presentation for a real case study. Recommended a company’s IPO by analyzing their financial position, creating a pro forma financial model, computing value with several valuation methodologies and examining IPO market conditions Member - MacIntalkers of Toastmasters International Apple Cupertino, CA Jul 2018 to Feb 2020 ● Delivered five public speeches under the “Dynamic Leadership” Pathways project. ● Developed effective communication skills on a weekly basis. \" \n",
    "\n",
    "def clean_input(resume):\n",
    "    resume = (resume.split(\" \"))\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    tokenize_remove_punct = RegexpTokenizer(r'\\w+')\n",
    "    lemma = WordNetLemmatizer()\n",
    "\n",
    "    # Cleaning descriptions for both the whole dataset and CO only\n",
    "    return clean_descriptions(stopWords, resume)\n",
    "\n",
    "resume = clean_input(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "78f96ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_resume = \"Tim Kasteler, Chemical Engineer tim.q.kasteler@gmail.comlinkedin.com/in/timqkasteler641-234-1466 Professional Summary Perceptive chemical engineer with 2+ years of experience. Skilled in process design and project management. Seeking to deliver out-of-the-box solutions at Agaffre, inc. At Lesiliti, lowered equipment malfunctions by 20% through improved work procedures and maintenance. Raised throughput 25% by designing two new production processes. Work Experience Chemical EngineerLesiliti, Inc.Feb 2017–May 2019    Slashed equipment malfunctions by 20% with improved work procedures and maintenance.    Trained 20 technicians and chemists in production best practices, cutting defects by 15%.    Designed and implemented new changeover procedures that saved 18 labor hours per week.    Increased throughput 25% through design of two new production processes. ChemistTrukgill, Inc.Feb 2016–Jan 2017    Developed new waste-stream treatment process that reduced waste output by 18%.    Created a new technique to retrieve by-products that saved $20,000 a year. Education 2011–2015 University of Northern IowaBachelor of Science in Chemical Engineering    Pursued a passion for process design coursework.    Conducted project in waste stream management that was written up in IChemE blog. Skills     Technical Skills: Project management, process design, testing, management    Soft Skills: Interpersonal skills, collaboration, communication, efficiency Activities  material   Leader of weekly fishing club.  financial  Article, “Waste Stream Management” published in Chemical Processing Blog.\"\n",
    "\n",
    "occupation = predict_one(model, ce_resume)\n",
    "ce_resume = clean_input(ce_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b9d66eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['site', 'data', 'development', 'control', 'quality']\n"
     ]
    }
   ],
   "source": [
    "# get difference between words \n",
    "def suggested_keywords(resume,occupation):\n",
    "# Generate list of key words for that class\n",
    "    suggested_words,key_words = [],[]\n",
    "    for i in range(len(d[occupation])):\n",
    "        key_words.append(d[occupation][i][0])\n",
    "\n",
    "# add to suggested words list if resume doesn't contain matching words\n",
    "    for i,key_word in enumerate(key_words):\n",
    "        if i > 10 and suggested_words == []:\n",
    "            contains_top_10 = True\n",
    "            return []\n",
    "        if key_word not in resume:\n",
    "            suggested_words.append(key_word)\n",
    "\n",
    "# Look through list of needed words\n",
    "# If any word stems begin with list of words to change, change it to a understandable output.\n",
    "    start_of_words_to_change = [\"financ\",\"analy\",\"engineer\", \"model\",]\n",
    "    for i,word in enumerate(suggested_words):\n",
    "        for check in start_of_words_to_change:\n",
    "            if word.startswith(check):\n",
    "                if check == \"financ\":\n",
    "                    suggested_words[i] = \"Variations of the word: finance\"\n",
    "\n",
    "                elif check == \"analy\":\n",
    "                    suggested_words[i] = \"Variations of the word: analysis\"\n",
    "\n",
    "                else:\n",
    "                    suggested_words[i] = f\"Variations of the word: {check}\"\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    return suggested_words[:5]\n",
    "\n",
    "if suggested_keywords(ce_resume,occupation) == []:\n",
    "    print(\"good job, you've got the top 10 words in your resume!\")\n",
    "else: print(suggested_keywords(ce_resume,occupation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d08670",
   "metadata": {},
   "source": [
    "\n",
    "Given training on job descriptions, the goal is that the model can classify into these clusters (with percentage fit/matching) with NEW inputs. \n",
    "\n",
    "PCA/Cosine Similarity with eigenvectors. Model tells us % similarity.\n",
    "\n",
    " - go back and look at how features fit into the clusters\n",
    " \n",
    "Find HTML template\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf39cfd7",
   "metadata": {},
   "source": [
    "# Recommend Jobs to Apply for Based On Resume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c37a82",
   "metadata": {},
   "source": [
    "\n",
    "how to predict top jobs\n",
    "- \n",
    "- based on current resume matchup, \n",
    "- spit out top 5 job URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b70ccf5",
   "metadata": {},
   "source": [
    "## Cosine Similarity Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "84631189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "# count_matrix = cv.fit_transform(cleaned_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "051b97f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_resume = \"Tim Kasteler, Chemical Engineertim.q.kasteler@gmail.comlinkedin.com/in/timqkasteler641-234-1466 Professional Summary Perceptive chemical engineer with 2+ years of experience. Skilled in process design and project management. Seeking to deliver out-of-the-box solutions at Agaffre, inc. At Lesiliti, lowered equipment malfunctions by 20% through improved work procedures and maintenance. Raised throughput 25% by designing two new production processes. Work Experience Chemical EngineerLesiliti, Inc.Feb 2017–May 2019    Slashed equipment malfunctions by 20% with improved work procedures and maintenance.    Trained 20 technicians and chemists in production best practices, cutting defects by 15%.    Designed and implemented new changeover procedures that saved 18 labor hours per week.    Increased throughput 25% through design of two new production processes. ChemistTrukgill, Inc.Feb 2016–Jan 2017    Developed new waste-stream treatment process that reduced waste output by 18%.    Created a new technique to retrieve by-products that saved $20,000 a year. Education 2011–2015 University of Northern IowaBachelor of Science in Chemical Engineering    Pursued a passion for process design coursework.    Conducted project in waste stream management that was written up in IChemE blog. Skills     Technical Skills: Project management, process design, testing, management    Soft Skills: Interpersonal skills, collaboration, communication, efficiency Activities     Leader of weekly fishing club.    Article, “Waste Stream Management” published in Chemical Processing Blog.\"\n",
    "\n",
    "occupation = predict_one(model, ce_resume)\n",
    "# ce_resume = clean_input(ce_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "3e67109b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>url</th>\n",
       "      <th>job_desc</th>\n",
       "      <th>job_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>Financial Analyst</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Position FP&amp;A (Financial Planning &amp; Analysis) ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>Financial Analyst</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>JOB SUMMARY:  Finance Analyst will oversee the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>Financial Analyst</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=c4884d2c3b54b...</td>\n",
       "      <td>Experienced in Clinical Trials budget</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>Financial Analyst</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Job Title: Financial Analyst Location: Houston...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>Financial Analyst</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Job Order: 171631, 12 month contractMAIN FUNCT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6555</th>\n",
       "      <td>Financial Analyst</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=84c63ad537ca3...</td>\n",
       "      <td>What will you contribute?  Reporting to the Co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6556</th>\n",
       "      <td>Financial Analyst</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=9a0948d88a043...</td>\n",
       "      <td>Financial Analyst II  The Texas Department of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6557</th>\n",
       "      <td>Financial Analyst</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=5d52cb4b0869b...</td>\n",
       "      <td>Financial Analyst, Treasury Location: Austin, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6558</th>\n",
       "      <td>Financial Analyst</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=7b50db55c775c...</td>\n",
       "      <td>TMD - Budget Analyst I-II (OSA Budget Analyst)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6559</th>\n",
       "      <td>Financial Analyst</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=cdf78113733ec...</td>\n",
       "      <td>WHO WE ARE:   The Teacher Retirement System of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1523 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              job_title                                                url  \\\n",
       "410   Financial Analyst  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "411   Financial Analyst  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "412   Financial Analyst  https://www.indeed.com/rc/clk?jk=c4884d2c3b54b...   \n",
       "413   Financial Analyst  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "414   Financial Analyst  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "...                 ...                                                ...   \n",
       "6555  Financial Analyst  https://www.indeed.com/rc/clk?jk=84c63ad537ca3...   \n",
       "6556  Financial Analyst  https://www.indeed.com/rc/clk?jk=9a0948d88a043...   \n",
       "6557  Financial Analyst  https://www.indeed.com/rc/clk?jk=5d52cb4b0869b...   \n",
       "6558  Financial Analyst  https://www.indeed.com/rc/clk?jk=7b50db55c775c...   \n",
       "6559  Financial Analyst  https://www.indeed.com/rc/clk?jk=cdf78113733ec...   \n",
       "\n",
       "                                               job_desc  job_id  \n",
       "410   Position FP&A (Financial Planning & Analysis) ...       1  \n",
       "411   JOB SUMMARY:  Finance Analyst will oversee the...       1  \n",
       "412               Experienced in Clinical Trials budget       1  \n",
       "413   Job Title: Financial Analyst Location: Houston...       1  \n",
       "414   Job Order: 171631, 12 month contractMAIN FUNCT...       1  \n",
       "...                                                 ...     ...  \n",
       "6555  What will you contribute?  Reporting to the Co...       1  \n",
       "6556  Financial Analyst II  The Texas Department of ...       1  \n",
       "6557  Financial Analyst, Treasury Location: Austin, ...       1  \n",
       "6558  TMD - Budget Analyst I-II (OSA Budget Analyst)...       1  \n",
       "6559  WHO WE ARE:   The Teacher Retirement System of...       1  \n",
       "\n",
       "[1523 rows x 4 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume = \"AQEEL ALI Aqeelali0312@gmail.com | (408) 718-0712 | www.linkedin.com/in/aqeelali786 EDUCATION: California Polytechnic University, San Luis Obispo, CA B.S. Business Administration – Financial Management Concentration Minor in Psychology ● Honors: Principal’s List (3.5+ GPA for three consecutive academic terms) - Fall 2019 ● Relevant Coursework: Financial Engineering in Risk Management, Computer Applications in Finance, Advanced Corporate Finance Chartered Financial Analyst Level Two Candidate Exam Date: Nov 2021 ● Pursuing CFA designation by acquiring a wide breadth of portfolio management skills. ● Level One Exam passed on June 2019. WORK EXPERIENCE: Middle Market Portfolio Analyst – Comerica Bank, San Jose, CA Jul 2019 to Present ● Analyze employer’s Middle Market business for the California region through industry, financial, macroeconomic data and other supporting credit information concerning an applicant's credit requests. ● Identify key business and financial risks that may impact the repayment prospects by the borrower. ● Expertise in Salesforce Data Management and CRM software systems utilized while underwriting to 8-figure commercial banking facilities ranging from $5M to $100M loans and facilities. aggregate exposure of bank assets. ● Prepare, review and assess the creditworthiness of commercial loan originations and renewals by evaluating tax returns, spreads of financial statements, historical trends, rent rolls, leases, projections, management performance, industry reports, cash flow models, capital structure and collateral analysis and other relevant data to analyze portfolio companies’ repayment capacity. ● Ensure the integrity of performance data for clientele and prospects and maintain ongoing relationships with thecustodial partners banks, vendors, and internal groups. ● Offer insights into customer financial needs, including opportunities identified using Line of Business-approved relationship expansion tools. Contribute personal insights related to a loan structure's effectiveness to mitigate risks, appropriate to prevailing competitive market environment and Bank risk tolerances. ● Prepared & presented nation-wide internal quarterly Company Q1 & Q2 2020 earnings reports and portfolio updates (within a team of four). ● Undertook special project initiative while fluidly adapting self-starter work ethic to a remote work environment during the initial rollout of Federal Treasury Payroll Protection Program and reviewed numerous applicants’ eligibility & fund usage during COVID-19 global pandemic. Venture Capital Analyst Intern - LDR Ventures, San Luis Obispo, CA Jan 2019 to Apr 2019 ● Analyzed investment opportunities up to $1.5M, prepared fundraising pitches to external stakeholders and prospective investors, and identified potential risks for early stage portfolio companies ● Assisted in building pricing models to help companies launch multiple new product lines and conduct stress tests under varying scenario analyses. ● Oversaw a personally proposed initiative for a portfolio company’s marketing campaign across universities in California. LEADERSHIP & OTHER RELEVANT EXPERIENCE Banking Valuations, Investment Banking Society San Luis Obispo, CA Jan 2019 to Feb 2019 ● Took an extracurricular course which covered the three main methods of company valuations ● Competed in a Goldman Sachs case competition against over 20 teams to create a pitch deck and presentation for a real case study. Recommended a company’s IPO by analyzing their financial position, creating a pro forma financial model, computing value with several valuation methodologies and examining IPO market conditions Member - MacIntalkers of Toastmasters International Apple Cupertino, CA Jul 2018 to Feb 2020 ● Delivered five public speeches under the “Dynamic Leadership” Pathways project. ● Developed effective communication skills on a weekly basis. \" \n",
    "lyft_job_descdesc = \"Financial Analyst, Strategy Finance at Lyft San Francisco, CA At Lyft, our mission is to improve people’s lives with the world’s best transportation. To do this, we start with our own community by creating an open, inclusive, and diverse organization.  Lyft is hiring a Financial Analyst for its Strategy Finance Team. The candidate in this position will provide financial and analytical support to drive strategic decisions for the company and help prepare financial management reporting. As a Financial Analyst, you will work directly with stakeholders across Finance in forecasting, planning and reporting key metrics to senior leadership.  Responsibilities: Help in analyzing & modeling forecast trends for total company financials Assist in the preparation and analysis of consolidated P&L for actuals and forecasts, help the FP&A team on deliverables, ongoing variance analysis, and ad hoc modeling Help lead the FP&A team through weekly and monthly forecasting Assist in the quarterly and annual strategic planning process Collaborate with Investor Relations by analyzing relevant financial information in preparation for the earnings call and investor presentations Team up with Corporate Development to create Board of Directors financials Partner with FP&A, Accounting, Treasury, Tax, and HR to forecast centralized expenses Drive monthly and quarterly close activities for FP&A and support consolidated management reporting Partner with Accounting to manage close timelines, process and reporting Manage creation of internal executive reporting documents including board, close and other management presentations and workbooks Support initiatives to create process efficiencies & improvements within FP&A Experience: BA/BS with 3+ years of experience in financial planning and analytics (FP&A) in a rigorous environment Corporate Finance, forecasting, or consolidations experience is a plus Detail-oriented and organized self-starter with a drive to dig into complex problems Advanced Excel skills. Experience building complex formulas and manipulating large data sets Ability to work in a fast-paced, team-based environment with minimal supervision Research, quantitative and analytical skills Comfortable navigating through financial statements Ability to organize and track overlapping tasks and assignments, with frequent priority changes Strong interpersonal and communication skills, with the ability to communicate and influence effectively across various departments Benefits: Great medical, dental, and vision insurance options Mental health benefits In addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off 401(k) plan to help save for your future 18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible Pre-tax commuter benefits Lyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership Program \" \n",
    "occupation = predict_one(model, resume)\n",
    "\n",
    "desc_df = df[df['job_title']==occupation]\n",
    "desc_df= desc_df.drop(columns = [\"Unnamed: 0\", \"Unnamed: 0.1\"])\n",
    "desc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "60abed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index into df where it matches occupation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "desc_df = df[df['job_title']==occupation]\n",
    "\n",
    "desc_df=desc_df.drop(columns = [\"Unnamed: 0\", \"Unnamed: 0.1\"])\n",
    "\n",
    "descs = list(desc_df[\"job_desc\"])\n",
    "\n",
    "d = {}\n",
    "for i in range(len(desc_df)):\n",
    "    url = desc_df.iloc[i,1]\n",
    "    desc = desc_df.iloc[i,2]\n",
    "    desc_matrix = cv.fit_transform([resume,desc])\n",
    "    d[url] = cosine_similarity(desc_matrix)[0][1]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "394c4c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://www.indeed.com/rc/clk?jk=431036bac7ce9ce4&fccid=65685d494d2217cd&vjs=3',\n",
       "  0.7186075327330236),\n",
       " ('https://www.indeed.com/rc/clk?jk=ec52df15ab9fece1&fccid=f54837e1fe3c9a9b&vjs=3',\n",
       "  0.714265525031642),\n",
       " ('https://www.indeed.com/rc/clk?jk=e2877e0f44c97bef&fccid=b662340f28f191b1&vjs=3',\n",
       "  0.7097361406153802),\n",
       " ('https://www.indeed.com/rc/clk?jk=c707c9d107647f01&fccid=f684144f16fda6a0&vjs=3',\n",
       "  0.7094554830651129),\n",
       " ('https://www.indeed.com/rc/clk?jk=39f9b9383977e464&fccid=cacc4984d9abfade&vjs=3',\n",
       "  0.7091143159085963)]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_d = [(k,v) for k, v in sorted(list(d.items()), key = lambda x : x[1])][::-1]\n",
    "sorted_d[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "547b54ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "matchPercentage =  round(cosine_similarity(resume_count_matrix)[0][1]*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f791001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.58"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchPercentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5534b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    LinearSVC()\n",
    "]\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = _split_data(df)\n",
    "# for _model in models:\n",
    "#     model = fit(_model,X_train,y_train)\n",
    "#     accuracies = cross_val_score(model, X_test, y_test, scoring='accuracy', cv=CV)\n",
    "#     for fold_idx, accuracy in enumerate(accuracies):\n",
    "#         entries.append((_model, fold_idx, accuracy))\n",
    "\n",
    "labels = df['job_title']\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "features = tfidf.fit_transform(df['job_desc']).toarray()\n",
    "\n",
    "for _model in models:\n",
    "    model_name = _model.__class__.__name__\n",
    "#     _model = _model.fit(X_train,y_train)\n",
    "    accuracies = cross_val_score(_model, features, labels, scoring='accuracy', cv=CV)\n",
    "    print(accuracies)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "        cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "    \n",
    "import seaborn as sns\n",
    "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df, size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "0fe054af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             model_name  fold_idx  accuracy\n",
      "0  LogisticRegression()         0  0.942605\n",
      "1  LogisticRegression()         1  0.955850\n",
      "2  LogisticRegression()         2  0.953642\n",
      "3  LogisticRegression()         3  0.955850\n",
      "4  LogisticRegression()         4  0.966814\n",
      "5           LinearSVC()         0  0.951435\n",
      "6           LinearSVC()         1  0.960265\n",
      "7           LinearSVC()         2  0.958057\n",
      "8           LinearSVC()         3  0.962472\n",
      "9           LinearSVC()         4  0.971239\n"
     ]
    }
   ],
   "source": [
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "print(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "80ec5e92",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'LinearSVC' and 'LogisticRegression'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36msafe_sort\u001b[0;34m(values, codes, na_sentinel, assume_unique, verify)\u001b[0m\n\u001b[1;32m   2122\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2123\u001b[0;31m             \u001b[0msorter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2124\u001b[0m             \u001b[0mordered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'LinearSVC' and 'LogisticRegression'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-275-8661b5b59f2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n\u001b[1;32m      5\u001b[0m               size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mboxplot\u001b[0;34m(x, y, hue, data, order, hue_order, orient, color, palette, saturation, width, dodge, fliersize, linewidth, whis, ax, **kwargs)\u001b[0m\n\u001b[1;32m   2238\u001b[0m ):\n\u001b[1;32m   2239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2240\u001b[0;31m     plotter = _BoxPlotter(x, y, hue, data, order, hue_order,\n\u001b[0m\u001b[1;32m   2241\u001b[0m                           \u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2242\u001b[0m                           width, dodge, fliersize, linewidth)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, hue, data, order, hue_order, orient, color, palette, saturation, width, dodge, fliersize, linewidth)\u001b[0m\n\u001b[1;32m    404\u001b[0m                  width, dodge, fliersize, linewidth):\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestablish_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestablish_colors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mestablish_variables\u001b[0;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;31m# Group the numeric data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 plot_data, value_label = self._group_longform(vals, groups,\n\u001b[0m\u001b[1;32m    207\u001b[0m                                                               group_names)\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36m_group_longform\u001b[0;34m(self, vals, grouper, order)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m                 \u001b[0mg_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrouped_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0mg_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mget_group\u001b[0;34m(self, name, obj)\u001b[0m\n\u001b[1;32m    841\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selected_obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m         \u001b[0minds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_get_index\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mSafe\u001b[0m \u001b[0mget\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslate\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdatelike\u001b[0m \u001b[0mto\u001b[0m \u001b[0munderlying\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \"\"\"\n\u001b[0;32m--> 672\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_get_indices\u001b[0;34m(self, names)\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m             \u001b[0mindex_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mindices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \"\"\"\n\u001b[1;32m    613\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assure_grouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mindices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;34m\"\"\" dict {group name -> group indices} \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         if len(self.groupings) == 1 and isinstance(\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCCategoricalIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         ):\n\u001b[1;32m    251\u001b[0m             \u001b[0;31m# This shows unused categories in indices GH#38642\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mresult_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresult_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompressed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupings\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mcodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstructed_codes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mresult_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalIndex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# set in __init__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrecode_from_groupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_grouper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mgroup_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgroup_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_codes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36m_make_codes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                 \u001b[0mna_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             codes, uniques = algorithms.factorize(\n\u001b[0m\u001b[1;32m    624\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mfactorize\u001b[0;34m(values, sort, na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msort\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         uniques, codes = safe_sort(\n\u001b[0m\u001b[1;32m    728\u001b[0m             \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massume_unique\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36msafe_sort\u001b[0;34m(values, codes, na_sentinel, assume_unique, verify)\u001b[0m\n\u001b[1;32m   2130\u001b[0m                 \u001b[0mordered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sort_tuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2132\u001b[0;31m                 \u001b[0mordered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sort_mixed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m     \u001b[0;31m# codes:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_sort_mixed\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   2182\u001b[0m     \u001b[0;34m\"\"\" order ints before strings in 1d arrays, safe in py3 \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2183\u001b[0m     \u001b[0mstr_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2184\u001b[0;31m     \u001b[0mnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mstr_pos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2185\u001b[0m     \u001b[0mstrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr_pos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2186\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msort\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m    989\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"K\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m     \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    992\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'LinearSVC' and 'LogisticRegression'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "labels = cv_df['model_name']\n",
    "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "plt.figure(20,20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606a84b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
