{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indeed Job Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "1. Get all of the URL's of EACH LISTING. for each page teh MAIN function gets, get the LINKS for that page (the job postings). For example 15 pages gets a list of 150 URLS. \n",
    "- for EACH page\n",
    "    - get Mosaic job card link\n",
    "    - iterate through the list of job cards\n",
    "    - append list of URLS by each individual URL\n",
    "    - move to next page in Indeed\n",
    "2. Look through the entire URL list and process them individually.\n",
    "- for each URL\n",
    "- extract the parts of the page for features \n",
    "3. On each individual page, 'write a row' for the data about the job as each features.\n",
    "\n",
    "Loop through list of URLs\n",
    "for each URLs, append a list by a dictionary of its contents\n",
    "dump into pd df\n",
    "pd.to_pickle('filepath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import csv\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(position, location,page_count):\n",
    "        if page_count > 0:\n",
    "            template = 'https://www.indeed.com/jobs?q={}&l={}&start={}'\n",
    "            page_count *= 10\n",
    "            url = template.format(position, location,page_count)\n",
    "        else:\n",
    "            template = 'https://www.indeed.com/jobs?q={}&l={}'\n",
    "            url = template.format(position, location)\n",
    "        \n",
    "        return 'http://api.scraperapi.com?api_key=f39a27865b56e74c0423ab1b9ecf1f23&url=' + url\n",
    "\n",
    "def job_listings_generator(position, location,page_count=10):\n",
    "    headers = {\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "    'accept-encoding': 'gzip, deflate, br',\n",
    "    'accept-language': 'en-US,en;q=0.9',\n",
    "    'cache-control': 'max-age=0',\n",
    "    'sec-fetch-dest': 'document',\n",
    "    'sec-fetch-mode': 'navigate',\n",
    "    'sec-fetch-site': 'none',\n",
    "    'sec-fetch-user': '?1',\n",
    "    'upgrade-insecure-requests': '1',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.67 Safari/537.36 Edg/87.0.664.47'\n",
    "}\n",
    "    \n",
    "    urls = [] \n",
    "    i = 0\n",
    "    \n",
    "    # POPULATE LIST OF URLs\n",
    "    \n",
    "    while i < page_count:\n",
    "        \n",
    "        url = get_url(position, location,i)  # create the url while passing in the position and location.\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        cards = soup.find( id = \"mosaic-zone-jobcards\" )\n",
    "        \n",
    "        if cards is None:\n",
    "            print('EMPTY URL HERE! ')\n",
    "            print(url)\n",
    "            time.sleep(6.8)\n",
    "            continue\n",
    "            \n",
    "        cards = cards.find_all('a')\n",
    "        cards_test = [card for card in cards if 'pagead' in card['href'] or '/rc/' in card['href']]\n",
    "        \n",
    "        for card in cards:\n",
    "            record = card['href']\n",
    "\n",
    "\n",
    "            if \"pagead\" in record:\n",
    "                urls.append(\"https://www.indeed.com\"+record)\n",
    "\n",
    "            if \"/rc/\" in record:\n",
    "                urls.append(\"https://www.indeed.com\"+record)\n",
    "        \n",
    "        time.sleep(0.1)\n",
    "        i += 1\n",
    "    \n",
    "    return urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_info(url,title,location):\n",
    "    try:\n",
    "        response = requests.get('http://api.scraperapi.com?api_key=4693573777e25967c50dbc4f37a1a3a8&url='+url)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        time.sleep(5.0)\n",
    "        try:\n",
    "            print('trying again!')\n",
    "            response = requests.get('http://api.scraperapi.com?api_key=4693573777e25967c50dbc4f37a1a3a8&url='+url)\n",
    "        except Exception as e:\n",
    "            return {}\n",
    "        \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    d = dict()\n",
    "    \n",
    "    \n",
    "    #location\n",
    "    d[\"location\"]=location\n",
    "    \n",
    "    #title\n",
    "    d[\"job_title\"]=title\n",
    "    \n",
    "    #posting URL\n",
    "    d[\"url\"] = url\n",
    "\n",
    "    \n",
    "    job_info = soup.find(class_=\"jobsearch-ViewJobLayout-jobDisplay icl-Grid-col icl-u-xs-span12 icl-u-lg-span7\" )\n",
    "    \n",
    "#     print(job_info)\n",
    "    \n",
    "    \n",
    "    if job_info is None:\n",
    "        d[\"job_desc\"] = \"\"\n",
    "#         time.sleep(6.8)\n",
    "        return d\n",
    "    \n",
    "        \n",
    "    cards = job_info.find_all('h2')\n",
    "    \n",
    "    if len(cards) == 0:\n",
    "        d[\"job_desc\"] = \"\"\n",
    "#         time.sleep(6.8)\n",
    "        return d\n",
    "            \n",
    "\n",
    "    #description\n",
    "    for card in cards:\n",
    "        d[\"job_desc\"]=card.find_next('div').text.replace(\"\\n\",\" \")\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished Houston listings for physician!\n",
      "EMPTY URL HERE! \n",
      "http://api.scraperapi.com?api_key=f39a27865b56e74c0423ab1b9ecf1f23&url=https://www.indeed.com/jobs?q=physician&l=San+Diego&start=10\n",
      "finished San+Diego listings for physician!\n",
      "finished Dallas listings for physician!\n",
      "EMPTY URL HERE! \n",
      "http://api.scraperapi.com?api_key=f39a27865b56e74c0423ab1b9ecf1f23&url=https://www.indeed.com/jobs?q=physician&l=San+Jose&start=40\n",
      "finished San+Jose listings for physician!\n",
      "finished Charlotte listings for physician!\n",
      "finished New+York listings for physician!\n",
      "finished Los+Angeles listings for physician!\n",
      "finished Chicago listings for physician!\n",
      "finished Phoenix listings for physician!\n",
      "finished Raleigh listings for physician!\n",
      "finished San+Francisco listings for physician!\n",
      "finished Portland listings for physician!\n",
      "finished Seattle listings for physician!\n",
      "finished Austin listings for physician!\n",
      "finished Houston listings for university+recruiter!\n",
      "finished San+Diego listings for university+recruiter!\n",
      "finished Dallas listings for university+recruiter!\n",
      "finished San+Jose listings for university+recruiter!\n",
      "finished Charlotte listings for university+recruiter!\n",
      "finished New+York listings for university+recruiter!\n",
      "finished Los+Angeles listings for university+recruiter!\n",
      "finished Chicago listings for university+recruiter!\n",
      "finished Phoenix listings for university+recruiter!\n",
      "finished Raleigh listings for university+recruiter!\n",
      "finished San+Francisco listings for university+recruiter!\n",
      "finished Portland listings for university+recruiter!\n",
      "finished Seattle listings for university+recruiter!\n",
      "finished Austin listings for university+recruiter!\n"
     ]
    }
   ],
   "source": [
    "# urls = []\n",
    "# locations = [\"major metros / areas\"]\n",
    "# titles = [\"10+ job titles\"]\n",
    "\n",
    "# titles = [\"data+scientist\",\"financial+analyst\", \"underwriter\",\"chemical+engineer\",\"physician\",\"university+recruiter\"]\n",
    "titles = [\"physician\",\"university+recruiter\"]\n",
    "\n",
    "locations = [\"Houston\",\"San+Diego\",\"Dallas\",\"San+Jose\",\"Charlotte\",'New+York','Los+Angeles','Chicago','Phoenix','Raleigh',\"San+Francisco\",\"Portland\", \"Seattle\",\"Austin\"]\n",
    "\n",
    "urls = []\n",
    "job_information = []\n",
    "\n",
    "\n",
    "for title in titles:\n",
    "    for location in locations:\n",
    "        urls=job_listings_generator(title,location,11)\n",
    "        for job in urls:\n",
    "            job_information.append(job_info(job,title,location))\n",
    "            \n",
    "            time.sleep(0.1)\n",
    "            \n",
    "        print(f\"finished {location} listings for {title}!\")\n",
    "Jupyter Notebook\n",
    "Indeed-Job-Desc-Scraper Last Checkpoint: 6 hours ago (autosaved) Current Kernel Logo \n",
    "\n",
    "Python 3\n",
    "\n",
    "    File\n",
    "    Edit\n",
    "    View\n",
    "    Insert\n",
    "    Cell\n",
    "    Kernel\n",
    "    Widgets\n",
    "    Help\n",
    "\n",
    "Indeed Job Scraper\n",
    "Steps\n",
    "\n",
    "    Get all of the URL's of EACH LISTING. for each page teh MAIN function gets, get the LINKS for that page (the job postings). For example 15 pages gets a list of 150 URLS.\n",
    "\n",
    "    for EACH page\n",
    "        get Mosaic job card link\n",
    "        iterate through the list of job cards\n",
    "        append list of URLS by each individual URL\n",
    "        move to next page in Indeed\n",
    "\n",
    "    Look through the entire URL list and process them individually.\n",
    "\n",
    "    for each URL\n",
    "    extract the parts of the page for features\n",
    "\n",
    "    On each individual page, 'write a row' for the data about the job as each features.\n",
    "\n",
    "Loop through list of URLs for each URLs, append a list by a dictionary of its contents dump into pd df pd.to_pickle('filepath')\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "\n",
    "import time\n",
    "\n",
    "import csv\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "from random import randint\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def get_url(position, location,page_count):\n",
    "\n",
    "        if page_count > 0:\n",
    "\n",
    "            template = 'https://www.indeed.com/jobs?q={}&l={}&start={}'\n",
    "\n",
    "            page_count *= 10\n",
    "\n",
    "            url = template.format(position, location,page_count)\n",
    "\n",
    "        else:\n",
    "\n",
    "            template = 'https://www.indeed.com/jobs?q={}&l={}'\n",
    "\n",
    "            url = template.format(position, location)\n",
    "\n",
    "        \n",
    "\n",
    "        return 'http://api.scraperapi.com?api_key=f39a27865b56e74c0423ab1b9ecf1f23&url=' + url\n",
    "\n",
    "​\n",
    "\n",
    "def job_listings_generator(position, location,page_count=10):\n",
    "\n",
    "    headers = {\n",
    "\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "\n",
    "    'accept-encoding': 'gzip, deflate, br',\n",
    "\n",
    "    'accept-language': 'en-US,en;q=0.9',\n",
    "\n",
    "    'cache-control': 'max-age=0',\n",
    "\n",
    "    'sec-fetch-dest': 'document',\n",
    "\n",
    "    'sec-fetch-mode': 'navigate',\n",
    "\n",
    "    'sec-fetch-site': 'none',\n",
    "\n",
    "    'sec-fetch-user': '?1',\n",
    "\n",
    "    'upgrade-insecure-requests': '1',\n",
    "\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.67 Safari/537.36 Edg/87.0.664.47'\n",
    "\n",
    "}\n",
    "\n",
    "    \n",
    "\n",
    "    urls = [] \n",
    "\n",
    "    i = 0\n",
    "\n",
    "    \n",
    "\n",
    "    # POPULATE LIST OF URLs\n",
    "\n",
    "    \n",
    "\n",
    "    while i < page_count:\n",
    "\n",
    "        \n",
    "\n",
    "        url = get_url(position, location,i)  # create the url while passing in the position and location.\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        cards = soup.find( id = \"mosaic-zone-jobcards\" )\n",
    "\n",
    "        \n",
    "\n",
    "        if cards is None:\n",
    "\n",
    "            print('EMPTY URL HERE! ')\n",
    "\n",
    "            print(url)\n",
    "\n",
    "            time.sleep(6.8)\n",
    "\n",
    "            continue\n",
    "\n",
    "            \n",
    "\n",
    "        cards = cards.find_all('a')\n",
    "\n",
    "        cards_test = [card for card in cards if 'pagead' in card['href'] or '/rc/' in card['href']]\n",
    "\n",
    "        \n",
    "\n",
    "        for card in cards:\n",
    "\n",
    "            record = card['href']\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "            if \"pagead\" in record:\n",
    "\n",
    "                urls.append(\"https://www.indeed.com\"+record)\n",
    "\n",
    "​\n",
    "\n",
    "            if \"/rc/\" in record:\n",
    "\n",
    "                urls.append(\"https://www.indeed.com\"+record)\n",
    "\n",
    "        \n",
    "\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    \n",
    "\n",
    "    return urls\n",
    "\n",
    "​\n",
    "\n",
    "def job_info(url,title,location):\n",
    "\n",
    "    try:\n",
    "\n",
    "        response = requests.get('http://api.scraperapi.com?api_key=4693573777e25967c50dbc4f37a1a3a8&url='+url)\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print(str(e))\n",
    "\n",
    "        time.sleep(5.0)\n",
    "\n",
    "        try:\n",
    "\n",
    "            print('trying again!')\n",
    "\n",
    "            response = requests.get('http://api.scraperapi.com?api_key=4693573777e25967c50dbc4f37a1a3a8&url='+url)\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            return {}\n",
    "\n",
    "        \n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    d = dict()\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    #location\n",
    "\n",
    "    d[\"location\"]=location\n",
    "\n",
    "    \n",
    "\n",
    "    #title\n",
    "\n",
    "    d[\"job_title\"]=title\n",
    "\n",
    "    \n",
    "\n",
    "    #posting URL\n",
    "\n",
    "    d[\"url\"] = url\n",
    "\n",
    "​\n",
    "\n",
    "    \n",
    "\n",
    "    job_info = soup.find(class_=\"jobsearch-ViewJobLayout-jobDisplay icl-Grid-col icl-u-xs-span12 icl-u-lg-span7\" )\n",
    "\n",
    "    \n",
    "\n",
    "#     print(job_info)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    if job_info is None:\n",
    "\n",
    "        d[\"job_desc\"] = \"\"\n",
    "\n",
    "#         time.sleep(6.8)\n",
    "\n",
    "        return d\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "    cards = job_info.find_all('h2')\n",
    "\n",
    "    \n",
    "\n",
    "    if len(cards) == 0:\n",
    "\n",
    "        d[\"job_desc\"] = \"\"\n",
    "\n",
    "#         time.sleep(6.8)\n",
    "\n",
    "        return d\n",
    "\n",
    "            \n",
    "\n",
    "​\n",
    "\n",
    "    #description\n",
    "\n",
    "    for card in cards:\n",
    "\n",
    "        d[\"job_desc\"]=card.find_next('div').text.replace(\"\\n\",\" \")\n",
    "\n",
    "​\n",
    "\n",
    "    return d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# urls = []\n",
    "# locations = [\"major metros / areas\"]\n",
    "# titles = [\"10+ job titles\"]\n",
    "\n",
    "# titles = [\"data+scientist\",\"financial+analyst\", \"underwriter\",\"chemical+engineer\",\"physician\",\"university+recruiter\"]\n",
    "titles = [\"data+scientist\",\"financial+analyst\"]\n",
    "locations = ['New+York',\"Dallas\", \"Charlotte\", \"San+Jose\", \"San+Diego\", \"Houston\",'Los+Angeles','Chicago','Phoenix','Raleigh',\"San+Francisco\",\"Portland\", \"Seattle\",\"New+York\",\"Los+Angeles\",\"Austin\"]\n",
    "\n",
    "urls = []\n",
    "job_information = []\n",
    "\n",
    "\n",
    "for title in titles:\n",
    "    if title == \"financial+analyst\":\n",
    "        locations = [\"San+Diego\", \"Houston\",'Los+Angeles','Chicago','Phoenix','Raleigh',\"San+Francisco\",\"Portland\", \"Seattle\",\"New+York\",\"Los+Angeles\",\"Austin\"]\n",
    "    for location in locations:\n",
    "        urls=job_listings_generator(title,location,10)\n",
    "        for job in urls:\n",
    "            job_information.append(job_info(job,title,location))\n",
    "            \n",
    "            time.sleep(0.1)\n",
    "            \n",
    "        print(f\"finished {location} listings for {title}!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>job_title</th>\n",
       "      <th>url</th>\n",
       "      <th>job_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Houston</td>\n",
       "      <td>physician</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>We are seeking a Physician BE/BC for a 3 month...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Houston</td>\n",
       "      <td>physician</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Flexible hoursWellness clinic/ regenerative me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Houston</td>\n",
       "      <td>physician</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>BC/BE Pediatrician Needed for Urgent Care Faci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Houston</td>\n",
       "      <td>physician</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Salary $200,000 + base, commensurate with expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Houston</td>\n",
       "      <td>physician</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Remote Telemedicine Opportunity -- Competitive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td>Austin</td>\n",
       "      <td>university+recruiter</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=fbfe5efc9fb57...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>Austin</td>\n",
       "      <td>university+recruiter</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Job Description: Actively source candidates to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>Austin</td>\n",
       "      <td>university+recruiter</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Austin Community College (ACC) is seeking qual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>Austin</td>\n",
       "      <td>university+recruiter</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=76b5eb2a8a234...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>Austin</td>\n",
       "      <td>university+recruiter</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=fbfe5efc9fb57...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2962 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     location             job_title  \\\n",
       "0     Houston             physician   \n",
       "1     Houston             physician   \n",
       "2     Houston             physician   \n",
       "3     Houston             physician   \n",
       "4     Houston             physician   \n",
       "...       ...                   ...   \n",
       "2957   Austin  university+recruiter   \n",
       "2958   Austin  university+recruiter   \n",
       "2959   Austin  university+recruiter   \n",
       "2960   Austin  university+recruiter   \n",
       "2961   Austin  university+recruiter   \n",
       "\n",
       "                                                    url  \\\n",
       "0     https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "1     https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "2     https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "3     https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "4     https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "...                                                 ...   \n",
       "2957  https://www.indeed.com/rc/clk?jk=fbfe5efc9fb57...   \n",
       "2958  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "2959  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "2960  https://www.indeed.com/rc/clk?jk=76b5eb2a8a234...   \n",
       "2961  https://www.indeed.com/rc/clk?jk=fbfe5efc9fb57...   \n",
       "\n",
       "                                               job_desc  \n",
       "0     We are seeking a Physician BE/BC for a 3 month...  \n",
       "1     Flexible hoursWellness clinic/ regenerative me...  \n",
       "2     BC/BE Pediatrician Needed for Urgent Care Faci...  \n",
       "3     Salary $200,000 + base, commensurate with expe...  \n",
       "4     Remote Telemedicine Opportunity -- Competitive...  \n",
       "...                                                 ...  \n",
       "2957                                                     \n",
       "2958  Job Description: Actively source candidates to...  \n",
       "2959  Austin Community College (ACC) is seeking qual...  \n",
       "2960                                                     \n",
       "2961                                                     \n",
       "\n",
       "[2962 rows x 4 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(job_information)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2196 entries, 0 to 2959\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  2196 non-null   int64 \n",
      " 1   location    2196 non-null   object\n",
      " 2   job_title   2196 non-null   object\n",
      " 3   url         2196 non-null   object\n",
      " 4   job_desc    2196 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 102.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_pickle(os.getcwd()+'/webscraped_pickle')\n",
    "df.to_csv('newscrape_ds_fa_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('newscrape_ds_fa_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2196 entries, 0 to 2195\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Unnamed: 0    2196 non-null   int64 \n",
      " 1   Unnamed: 0.1  2196 non-null   int64 \n",
      " 2   location      2196 non-null   object\n",
      " 3   job_title     2196 non-null   object\n",
      " 4   url           2196 non-null   object\n",
      " 5   job_desc      2196 non-null   object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 120.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>location</th>\n",
       "      <th>job_title</th>\n",
       "      <th>url</th>\n",
       "      <th>job_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>2950</td>\n",
       "      <td>2950</td>\n",
       "      <td>Austin</td>\n",
       "      <td>university+recruiter</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Austin Community College (ACC) is seeking qual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>2954</td>\n",
       "      <td>2954</td>\n",
       "      <td>Austin</td>\n",
       "      <td>university+recruiter</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Job Description: Actively source candidates to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>2955</td>\n",
       "      <td>2955</td>\n",
       "      <td>Austin</td>\n",
       "      <td>university+recruiter</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Austin Community College (ACC) is seeking qual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>2958</td>\n",
       "      <td>2958</td>\n",
       "      <td>Austin</td>\n",
       "      <td>university+recruiter</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Job Description: Actively source candidates to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>2959</td>\n",
       "      <td>2959</td>\n",
       "      <td>Austin</td>\n",
       "      <td>university+recruiter</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Austin Community College (ACC) is seeking qual...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1 location             job_title  \\\n",
       "2191        2950          2950   Austin  university+recruiter   \n",
       "2192        2954          2954   Austin  university+recruiter   \n",
       "2193        2955          2955   Austin  university+recruiter   \n",
       "2194        2958          2958   Austin  university+recruiter   \n",
       "2195        2959          2959   Austin  university+recruiter   \n",
       "\n",
       "                                                    url  \\\n",
       "2191  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "2192  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "2193  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "2194  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "2195  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "\n",
       "                                               job_desc  \n",
       "2191  Austin Community College (ACC) is seeking qual...  \n",
       "2192  Job Description: Actively source candidates to...  \n",
       "2193  Austin Community College (ACC) is seeking qual...  \n",
       "2194  Job Description: Actively source candidates to...  \n",
       "2195  Austin Community College (ACC) is seeking qual...  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.info()\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "physician               1462\n",
       "university+recruiter     734\n",
       "Name: job_title, dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['job_title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('newscrape_ds_fa_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPROGRESS BAR!\\n - how far the scraper got for each occupation\\n\"data+scientist\" - Charlotte \\n\"financial+analyst\" - San Jose\\n\"underwriter\" - DONE\\n\"chemical+engineer\" - DONE \\n\"physician\" - Los Angeles\\n\"university+recruiter\"\\n'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "PROGRESS BAR!\n",
    " - how far the scraper got for each occupation\n",
    "\"data+scientist\" - Charlotte \n",
    "\"financial+analyst\" - San Jose\n",
    "\"underwriter\" - DONE\n",
    "\"chemical+engineer\" - DONE \n",
    "\"physician\" - Los Angeles\n",
    "\"university+recruiter\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
