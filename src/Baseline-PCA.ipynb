{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b4cb6b",
   "metadata": {},
   "source": [
    "## PCA and Clustering \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1765c9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "665c339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Cleaned_Job_desc_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53f67795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "financial+analyst    482\n",
       "data+scientist       371\n",
       "physician            325\n",
       "underwriter          299\n",
       "chemical+engineer    252\n",
       "recruiter            248\n",
       "Name: job_title, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Disparity / Class Balance Check\n",
    "df['job_title'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "838717cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(stopWoFinancrds, descriptions):\n",
    "    cleaned_descriptions = []\n",
    "    for description in descriptions:\n",
    "        temp_list = []\n",
    "        for word in description.split():\n",
    "            if word not in stopWords:\n",
    "                temp_list.append(word.lower())\n",
    "        cleaned_descriptions.append(' '.join(temp_list))\n",
    "    return np.array(cleaned_descriptions)\n",
    "\n",
    "def remove_punctuation(descriptions):\n",
    "    no_punct_descriptions = []\n",
    "    for description in descriptions:\n",
    "        description_no_punct = ' '.join(RegexpTokenizer(r'\\w+').tokenize(description))\n",
    "        no_punct_descriptions.append(description_no_punct)\n",
    "    return np.array(no_punct_descriptions)\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    # nltk.download()\n",
    "\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {'J': wordnet.ADJ,\n",
    "               'N': wordnet.NOUN,\n",
    "               'V': wordnet.VERB,\n",
    "               'R': wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def lemmatize_descriptions(descriptions):\n",
    "    cleaned_descriptions = []\n",
    "    for description in descriptions:\n",
    "        temp_list = []\n",
    "        for word in description.split():\n",
    "            cleaned_word = WordNetLemmatizer().lemmatize(word, get_wordnet_pos(word))\n",
    "            temp_list.append(cleaned_word)\n",
    "        cleaned_descriptions.append(' '.join(temp_list))\n",
    "    return np.array(cleaned_descriptions)\n",
    "\n",
    "def clean_descriptions(stopWords, descriptions):\n",
    "    no_punct = remove_punctuation(descriptions)\n",
    "    no_punct_sw = remove_stopwords(stopWords, no_punct)\n",
    "    cleaned = lemmatize_descriptions(no_punct_sw)\n",
    "    return cleaned\n",
    "\n",
    "def get_representative_jobs(df, kmeans):\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    for cent in cluster_centers:\n",
    "        print('\\nCluster Represnetations')\n",
    "        dist = euclidean_distances(cent.reshape(1,-1), tfidf)\n",
    "        order = np.argsort(dist)\n",
    "        for o in order[0][:5]:\n",
    "            title = df['job_title'].iloc[o]\n",
    "            print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c55d937a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr path is:\n",
      "/home/aqeelali7/Documents/Galvanize/Capstone-3-ATS/The-Right-Resume/src\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import os\n",
    "    print(\"curr path is:\")\n",
    "    print(os.getcwd())\n",
    "    \n",
    "\n",
    "\n",
    "    # Reading in data\n",
    "    df = pd.read_csv('../data/Cleaned_data_Set_5_jobs')\n",
    "    df=df.drop(columns = \"location\")\n",
    "#     print(df['job_desc'])\n",
    "    descriptions = df['job_desc'].values\n",
    "\n",
    "    # Creating stop words\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    add_stopwords = {\n",
    "        'join', 'work', 'team', 'future', 'digital', 'technology', 'access', 'leader', 'industry', 'history', 'innovation',\n",
    "        'year', 'customer', 'focused', 'leading', 'business', 'ability', 'country', 'employee', 'www', 'seeking',\n",
    "        'location', 'role', 'responsible', 'designing', 'code', 'ideal', 'candidate', 'also', 'duty', 'without', 'excellent',\n",
    "        'set', 'area', 'well', 'use', 'strong', 'self', 'help', 'diverse', 'every', 'day', 'equal', 'employment', 'opportunity',\n",
    "        'affirmative', 'action', 'employer', 'diversity', 'qualified', 'applicant', 'receive', 'consideration', 'regard',\n",
    "        'race', 'color', 'religion', 'sex', 'national', 'origin', 'status', 'age', 'sexual', 'orientation', 'gender',\n",
    "        'identity', 'disability', 'marital', 'family', 'medical', 'protected', 'veteran', 'reasonable', 'accomodation',\n",
    "        'protect', 'status', 'equal', 'discriminate', 'inclusive', 'diverse'\n",
    "    }\n",
    "    \n",
    "    stopWords = stopWords.union(add_stopwords)\n",
    "\n",
    "    # Initializing punctuation remover and lemmatizer\n",
    "    tokenize_remove_punct = RegexpTokenizer(r'\\w+')\n",
    "    lemma = WordNetLemmatizer()\n",
    "\n",
    "    # Cleaning descriptions for both the whole dataset and CO only\n",
    "    cleaned_descriptions = clean_descriptions(stopWords, descriptions)\n",
    "\n",
    "    # Vectorizing words creating both tf and tf-idf matrices\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words=stopWords, min_df=.15, max_df=0.75, max_features=5000)\n",
    "    tfidf = tfidf_vectorizer.fit_transform(cleaned_descriptions).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff057a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aqeelali7/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:792: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster Represnetations\n",
      "physician\n",
      "physician\n",
      "physician\n",
      "physician\n",
      "chemical+engineer\n",
      "\n",
      "Cluster Represnetations\n",
      "physician\n",
      "physician\n",
      "physician\n",
      "physician\n",
      "physician\n",
      "\n",
      "Cluster Represnetations\n",
      "financial+analyst\n",
      "financial+analyst\n",
      "financial+analyst\n",
      "financial+analyst\n",
      "financial+analyst\n",
      "\n",
      "Cluster Represnetations\n",
      "physician\n",
      "chemical+engineer\n",
      "physician\n",
      "chemical+engineer\n",
      "chemical+engineer\n",
      "\n",
      "Cluster Represnetations\n",
      "chemical+engineer\n",
      "physician\n",
      "chemical+engineer\n",
      "physician\n",
      "chemical+engineer\n",
      "\n",
      "Cluster Represnetations\n",
      "physician\n",
      "physician\n",
      "chemical+engineer\n",
      "physician\n",
      "chemical+engineer\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    # Initializing and fitting k-means model\n",
    "    kmeans = KMeans(n_clusters=6, n_jobs=-1)\n",
    "    kmeans.fit(tfidf)\n",
    "\n",
    "    # Returning most representative words for each cluster\n",
    "    get_representative_jobs(df, kmeans)\n",
    "\n",
    "    # Calculating model score for kmeans\n",
    "    silhouette_score(tfidf, kmeans.labels_)\n",
    "    kmeans.score(tfidf)\n",
    "    \n",
    "    #Visualizing k-means clusters with PCA graph\n",
    "    kmeans_model = kmeans\n",
    "    labels=kmeans_model.labels_.tolist()\n",
    "\n",
    "    pca = PCA(n_components=2).fit(tfidf)\n",
    "    datapoint = pca.transform(tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c25ec398",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8499806c679a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"#FFFF00\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"#008000\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"#0000FF\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"#FF0000\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"#33fff6\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatapoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-8499806c679a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"#FFFF00\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"#008000\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"#0000FF\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"#FF0000\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"#33fff6\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatapoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "    plt.figure\n",
    "\n",
    "    label1 = [\"#FFFF00\", \"#008000\", \"#0000FF\", \"#FF0000\",\"#33fff6\"]\n",
    "    color = [label1[i] for i in labels]\n",
    "    plt.scatter(datapoint[:, 0], datapoint[:, 1], c=color)\n",
    "    centroids = kmeans_model.cluster_centers_\n",
    "    centroidpoint = pca.transform(centroids)\n",
    "    plt.scatter(centroidpoint[:,0], centroidpoint[:,1], marker='^', s=150, c=\"#000000\", label='Cluster Centers')\n",
    "    plt.xlabel('First PCA Dimension')\n",
    "    plt.ylabel('Second PCA Dimension')\n",
    "    plt.title('K-Means Clusters')\n",
    "    plt.legend(fontsize='x-small')\n",
    "    plt.text(0.44,0.6, 'Blue: Mobile devs', fontsize=9)\n",
    "    plt.text(0.44, 0.5, 'Yellow: Data science', fontsize=9)\n",
    "    plt.text(0.44, 0.4, 'Green: Big data dev', fontsize=9)\n",
    "    plt.text(0.44, 0.4, 'Red: Big data dev', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "#     plt.savefig('../imgs/pca_kmeans_3_clusters.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d08670",
   "metadata": {},
   "source": [
    "\n",
    "Given training on job descriptions, the goal is that the model can classify into these clusters (with percentage fit/matching) with NEW inputs. \n",
    "\n",
    "PCA/Cosine Similarity with eigenvectors. Model tells us % similarity.\n",
    "\n",
    " - go back and look at how features fit into the clusters\n",
    " \n",
    "Find HTML template\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf39cfd7",
   "metadata": {},
   "source": [
    "### Run model (some sort of linear model)\n",
    "#### Find Feature significance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcacfbc",
   "metadata": {},
   "source": [
    "## LDA for Feature Importance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b70ccf5",
   "metadata": {},
   "source": [
    "## Cosine Similarity Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "84631189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "count_matrix = cv.fit_transform(cleaned_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3e67109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = \"AQEEL ALI Aqeelali0312@gmail.com | (408) 718-0712 | www.linkedin.com/in/aqeelali786 EDUCATION: California Polytechnic University, San Luis Obispo, CA B.S. Business Administration – Financial Management Concentration Minor in Psychology ● Honors: Principal’s List (3.5+ GPA for three consecutive academic terms) - Fall 2019 ● Relevant Coursework: Financial Engineering in Risk Management, Computer Applications in Finance, Advanced Corporate Finance Chartered Financial Analyst Level Two Candidate Exam Date: Nov 2021 ● Pursuing CFA designation by acquiring a wide breadth of portfolio management skills. ● Level One Exam passed on June 2019. WORK EXPERIENCE: Middle Market Portfolio Analyst – Comerica Bank, San Jose, CA Jul 2019 to Present ● Analyze employer’s Middle Market business for the California region through industry, financial, macroeconomic data and other supporting credit information concerning an applicant's credit requests. ● Identify key business and financial risks that may impact the repayment prospects by the borrower. ● Expertise in Salesforce Data Management and CRM software systems utilized while underwriting to 8-figure commercial banking facilities ranging from $5M to $100M loans and facilities. aggregate exposure of bank assets. ● Prepare, review and assess the creditworthiness of commercial loan originations and renewals by evaluating tax returns, spreads of financial statements, historical trends, rent rolls, leases, projections, management performance, industry reports, cash flow models, capital structure and collateral analysis and other relevant data to analyze portfolio companies’ repayment capacity. ● Ensure the integrity of performance data for clientele and prospects and maintain ongoing relationships with thecustodial partners banks, vendors, and internal groups. ● Offer insights into customer financial needs, including opportunities identified using Line of Business-approved relationship expansion tools. Contribute personal insights related to a loan structure's effectiveness to mitigate risks, appropriate to prevailing competitive market environment and Bank risk tolerances. ● Prepared & presented nation-wide internal quarterly Company Q1 & Q2 2020 earnings reports and portfolio updates (within a team of four). ● Undertook special project initiative while fluidly adapting self-starter work ethic to a remote work environment during the initial rollout of Federal Treasury Payroll Protection Program and reviewed numerous applicants’ eligibility & fund usage during COVID-19 global pandemic. Venture Capital Analyst Intern - LDR Ventures, San Luis Obispo, CA Jan 2019 to Apr 2019 ● Analyzed investment opportunities up to $1.5M, prepared fundraising pitches to external stakeholders and prospective investors, and identified potential risks for early stage portfolio companies ● Assisted in building pricing models to help companies launch multiple new product lines and conduct stress tests under varying scenario analyses. ● Oversaw a personally proposed initiative for a portfolio company’s marketing campaign across universities in California. LEADERSHIP & OTHER RELEVANT EXPERIENCE Banking Valuations, Investment Banking Society San Luis Obispo, CA Jan 2019 to Feb 2019 ● Took an extracurricular course which covered the three main methods of company valuations ● Competed in a Goldman Sachs case competition against over 20 teams to create a pitch deck and presentation for a real case study. Recommended a company’s IPO by analyzing their financial position, creating a pro forma financial model, computing value with several valuation methodologies and examining IPO market conditions Member - MacIntalkers of Toastmasters International Apple Cupertino, CA Jul 2018 to Feb 2020 ● Delivered five public speeches under the “Dynamic Leadership” Pathways project. ● Developed effective communication skills on a weekly basis. \" \n",
    "lyft_job_desc = \"Financial Analyst, Strategy Finance at Lyft San Francisco, CA At Lyft, our mission is to improve people’s lives with the world’s best transportation. To do this, we start with our own community by creating an open, inclusive, and diverse organization.  Lyft is hiring a Financial Analyst for its Strategy Finance Team. The candidate in this position will provide financial and analytical support to drive strategic decisions for the company and help prepare financial management reporting. As a Financial Analyst, you will work directly with stakeholders across Finance in forecasting, planning and reporting key metrics to senior leadership.  Responsibilities: Help in analyzing & modeling forecast trends for total company financials Assist in the preparation and analysis of consolidated P&L for actuals and forecasts, help the FP&A team on deliverables, ongoing variance analysis, and ad hoc modeling Help lead the FP&A team through weekly and monthly forecasting Assist in the quarterly and annual strategic planning process Collaborate with Investor Relations by analyzing relevant financial information in preparation for the earnings call and investor presentations Team up with Corporate Development to create Board of Directors financials Partner with FP&A, Accounting, Treasury, Tax, and HR to forecast centralized expenses Drive monthly and quarterly close activities for FP&A and support consolidated management reporting Partner with Accounting to manage close timelines, process and reporting Manage creation of internal executive reporting documents including board, close and other management presentations and workbooks Support initiatives to create process efficiencies & improvements within FP&A Experience: BA/BS with 3+ years of experience in financial planning and analytics (FP&A) in a rigorous environment Corporate Finance, forecasting, or consolidations experience is a plus Detail-oriented and organized self-starter with a drive to dig into complex problems Advanced Excel skills. Experience building complex formulas and manipulating large data sets Ability to work in a fast-paced, team-based environment with minimal supervision Research, quantitative and analytical skills Comfortable navigating through financial statements Ability to organize and track overlapping tasks and assignments, with frequent priority changes Strong interpersonal and communication skills, with the ability to communicate and influence effectively across various departments Benefits: Great medical, dental, and vision insurance options Mental health benefits In addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off 401(k) plan to help save for your future 18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible Pre-tax commuter benefits Lyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership Program \" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0d4e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_count_matrix = cv.fit_transform([resume,lyft_job_desc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ebd47a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "49010ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.65583356]\n",
      " [0.65583356 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarity(resume_count_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "547b54ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "matchPercentage =  round(cosine_similarity(resume_count_matrix)[0][1]*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3f791001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.58"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchPercentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e967cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "6 job titles [  DS_words   |  FA_words |  CE_words ]\n",
    "input text   [ %fit        |           |           ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfc1571",
   "metadata": {},
   "outputs": [],
   "source": [
    "FA_profile = \"Finance\" --> \"financ\"\n",
    "IF name LIKE financ% \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
